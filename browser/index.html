<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HLSF Cognition Engine v2.0</title>
  <style>
    :root {
      color-scheme: dark;
      --bg: #0a0a0a;
      --panel: #111;
      --text: #e0e0e0;
      --accent: #00ff88;
      --error: #ff4444;
      --success: #44ff44;
      --warning: #ffd54f;
      --scrollbar: #1f1f1f;
    }

    * { box-sizing: border-box; }

    body {
      margin: 0;
      font-family: 'Fira Code', Consolas, Monaco, 'Courier New', monospace;
      background: var(--bg);
      color: var(--text);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }

    #app {
      flex: 1;
      display: flex;
      flex-direction: column;
      max-width: 1200px;
      margin: 0 auto;
      padding: 1.5rem;
      width: 100%;
    }

    #header {
      font-size: 1.3rem;
      font-weight: bold;
      margin-bottom: 1rem;
      color: var(--accent);
      display: flex;
      align-items: center;
      justify-content: space-between;
      flex-wrap: wrap;
      gap: 1rem;
    }

    .header-stats {
      display: flex;
      gap: 1.5rem;
      font-size: 0.9rem;
      font-weight: normal;
    }

    .stat-item {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
    }

    .stat-label {
      font-size: 0.75rem;
      opacity: 0.6;
    }

    .stat-value {
      font-weight: bold;
      color: var(--accent);
    }

    #log {
      flex: 1;
      background: var(--panel);
      border: 1px solid #222;
      border-radius: 12px;
      padding: 1rem;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: 1rem;
      box-shadow: 0 0 20px rgba(0, 255, 136, 0.1);
      min-height: 400px;
    }

    #log::-webkit-scrollbar {
      width: 10px;
    }

    #log::-webkit-scrollbar-thumb {
      background: var(--scrollbar);
      border-radius: 10px;
    }

    #input-area {
      margin-top: 1rem;
      display: flex;
      gap: 0.75rem;
    }

    #command-input {
      flex: 1;
      padding: 0.75rem 1rem;
      background: var(--panel);
      border: 1px solid #222;
      border-radius: 8px;
      color: var(--text);
      font-size: 1rem;
      transition: border 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
    }

    #command-input:focus {
      outline: none;
      border-color: var(--accent);
      box-shadow: 0 0 0 2px rgba(0, 255, 136, 0.2);
    }

    .button-group {
      display: flex;
      gap: 0.5rem;
    }

    .btn {
      padding: 0.75rem 1.5rem;
      border: none;
      border-radius: 8px;
      font-size: 1rem;
      font-weight: bold;
      cursor: pointer;
      transition: transform 0.15s ease, box-shadow 0.15s ease;
    }

    .btn-primary {
      background: var(--accent);
      color: #022d15;
    }

    .btn-secondary {
      background: #333;
      color: var(--text);
    }

    .btn:hover:not(:disabled) {
      transform: translateY(-1px);
      box-shadow: 0 10px 25px rgba(0, 255, 136, 0.25);
    }

    .btn:disabled {
      opacity: 0.6;
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }

    .log-entry {
      border-left: 3px solid var(--accent);
      padding-left: 1rem;
      animation: fadeIn 0.3s ease;
    }

    .log-entry .timestamp {
      font-size: 0.75rem;
      opacity: 0.6;
    }

    .log-entry.status { font-style: italic; }
    .log-entry.error { border-left-color: var(--error); color: var(--error); }
    .log-entry.success { border-left-color: var(--success); color: var(--success); }
    .log-entry.warning { border-left-color: var(--warning); color: var(--warning); }

    .cost-estimate {
      background: rgba(255, 213, 79, 0.1);
      border: 1px solid var(--warning);
      border-radius: 8px;
      padding: 0.75rem;
      margin: 0.5rem 0;
    }

    .cost-estimate-title {
      font-weight: bold;
      color: var(--warning);
      margin-bottom: 0.5rem;
    }

    details {
      background: rgba(255, 255, 255, 0.02);
      border: 1px solid #222;
      border-radius: 8px;
      padding: 0.5rem 0.75rem;
      transition: border 0.2s ease;
    }

    details[open] {
      border-color: var(--accent);
      box-shadow: 0 0 0 1px rgba(0, 255, 136, 0.25);
    }

    summary {
      cursor: pointer;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      list-style: none;
      font-weight: 600;
    }

    summary::-webkit-details-marker { display: none; }

    .status-badge {
      font-size: 0.75rem;
      padding: 0.1rem 0.35rem;
      border-radius: 999px;
      background: rgba(255, 255, 255, 0.08);
      color: var(--text);
    }

    .attention-badge {
      font-weight: bold;
      padding: 0.15rem 0.45rem;
      border-radius: 999px;
      color: #011;
    }

    .attention-high { background: #00ff88; }
    .attention-medium { background: #ffd54f; }
    .attention-low { background: #ff7777; }
    .attention-hub { background: #4aa3ff; color: #021226; }
    .attention-bridge { background: #bf7fff; color: #220031; }

    .modal {
      position: fixed;
      inset: 0;
      backdrop-filter: blur(8px);
      background: rgba(0, 0, 0, 0.7);
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 999;
    }

    .modal.hidden { display: none; }

    .modal-content {
      background: #111;
      border: 1px solid var(--accent);
      border-radius: 12px;
      padding: 2rem;
      width: min(420px, 90vw);
      display: flex;
      flex-direction: column;
      gap: 1rem;
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4);
    }

    .modal-content h2 {
      margin: 0;
      color: var(--accent);
    }

    .modal-content input {
      padding: 0.75rem 1rem;
      border-radius: 8px;
      border: 1px solid #222;
      background: #0c0c0c;
      color: var(--text);
      font-size: 1rem;
    }

    .modal-actions {
      display: flex;
      justify-content: flex-end;
      gap: 0.75rem;
    }

    .pill-button {
      border-radius: 999px;
      border: none;
      padding: 0.5rem 1.4rem;
      font-weight: bold;
      cursor: pointer;
      transition: transform 0.15s ease, box-shadow 0.15s ease;
    }

    .pill-button.primary { background: var(--accent); color: #022d15; }
    .pill-button.secondary { background: transparent; border: 1px solid #333; color: var(--text); }

    .pill-button:disabled {
      opacity: 0.6;
      cursor: not-allowed;
      transform: none;
      box-shadow: none;
    }

    .pill-button:not(:disabled):hover {
      transform: translateY(-1px);
      box-shadow: 0 10px 25px rgba(0, 255, 136, 0.18);
    }

    .processing-indicator {
      display: inline-flex;
      align-items: center;
      gap: 0.35rem;
    }

    .spinner {
      width: 14px;
      height: 14px;
      border-radius: 50%;
      border: 2px solid rgba(0, 255, 136, 0.15);
      border-top-color: var(--accent);
      animation: spin 0.8s linear infinite;
    }

    .final-output {
      border-left: 3px solid var(--success);
      padding-left: 1rem;
      background: rgba(68, 255, 68, 0.05);
    }

    .final-output h3 {
      margin-top: 0;
      color: var(--success);
    }

    .final-output pre {
      background: rgba(0, 0, 0, 0.35);
      padding: 0.75rem;
      border-radius: 8px;
      overflow-x: auto;
      white-space: pre-wrap;
      word-wrap: break-word;
    }

    .json-key { color: #64b5f6; }
    .json-string { color: #f48fb1; }
    .json-number { color: #ffb74d; }
    .json-boolean { color: #81c784; }

    @media (max-width: 720px) {
      #app { padding: 1rem; }
      #header { flex-direction: column; align-items: flex-start; }
      .header-stats { flex-direction: column; gap: 0.5rem; }
      #input-area { flex-direction: column; }
      .button-group { flex-direction: column; }
      .btn { width: 100%; }
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(6px); }
      to { opacity: 1; transform: translateY(0); }
    }

    @keyframes spin {
      from { transform: rotate(0deg); }
      to { transform: rotate(360deg); }
    }
  </style>
</head>
<body>
  <div id="api-modal" class="modal">
    <div class="modal-content" role="dialog" aria-modal="true">
      <h2>Enter OpenAI API Key</h2>
      <p>Provide your OpenAI API key (sk-...) to begin using the HLSF Cognition Engine.</p>
      <input id="api-key-input" type="password" placeholder="sk-..." aria-label="OpenAI API key" />
      <div class="modal-actions">
        <button id="api-cancel" class="pill-button secondary">Continue offline</button>
        <button id="api-confirm" class="pill-button primary">Save key</button>
      </div>
      <small style="opacity:0.65">⚠️ Warning: Key stored in browser memory only. For production use, consider a backend proxy.</small>
    </div>
  </div>

  <div id="app" aria-live="polite">
    <div id="header">
      <div>HLSF Cognition Engine v2.0</div>
      <div class="header-stats">
        <div class="stat-item">
          <span class="stat-label">Cache Hit Rate</span>
          <span class="stat-value" id="cache-hit-rate">—</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">Cached Tokens</span>
          <span class="stat-value" id="cached-tokens">—</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">Session Cost</span>
          <span class="stat-value" id="session-cost">$0.00</span>
        </div>
      </div>
    </div>
    <div id="log" aria-label="Command log"></div>
    <div id="input-area">
      <input id="command-input" type="text" placeholder="> Enter a prompt or /command" maxlength="600" autocomplete="off" aria-label="Command input" />
      <div class="button-group">
        <button id="cancel-btn" class="btn btn-secondary" style="display: none;">Cancel</button>
        <button id="send-btn" class="btn btn-primary">Send</button>
      </div>
    </div>
  </div>

  <script>
    // ============================================
    // CONSTANTS & CONFIGURATION
    // ============================================
    const CONFIG = {
      MAX_TOKENS_PER_PROMPT: 100,
      MAX_CONCURRENCY: 5,
      MAX_RETRY_ATTEMPTS: 3,
      RETRY_BASE_DELAY_MS: 500,
      DEFAULT_MODEL: 'gpt-4o-mini', // Cheaper model
      MAX_SESSION_HISTORY: 50,
      ESTIMATED_COST_PER_API_CALL: 0.02, // $0.02 per call (conservative estimate)
    };

    const RELATIONSHIP_PRIORITIES = new Map([
      ['≡', 1.0], ['⊃', 1.0], ['⊂', 0.8], ['≈', 0.7], ['∈', 0.9], ['∋', 0.9],
      ['⊤', 0.9], ['⊥', 0.9], ['⊏', 0.8], ['⊐', 0.8], ['↔', 0.7], ['⇌', 0.7],
      ['∥', 0.6], ['∼', 0.5], ['→', 0.5], ['⇒', 0.5], ['⇐', 0.5], ['↠', 0.5],
      ['↗', 0.4], ['↘', 0.4], ['⇝', 1.0], ['⇂', 0.7], ['≠', 0.8], ['⊕', 0.8],
      ['⊛', 0.7], ['∝', 0.7], ['⇝ Causes', 1.0], ['⇐ Caused By', 0.9],
      ['∗', 0.7], ['≜', 0.9], ['⋆', 0.8], ['7→', 0.7], ['⊢', 0.9], ['⊣', 0.9],
      ['↷', 0.8], ['↶', 0.8], ['◦', 0.9], ['|=', 0.9], ['◁', 0.6], ['⇄', 0.6],
      ['⊗', 0.9], ['÷', 0.7], ['⊘', 0.8], ['×', 0.8], ['¬', 0.8], ['†', 0.8],
      ['⊠', 0.8], ['/∈', 0.8], ['⊬', 0.8], ['⊩', 0.9], ['⊨', 0.9], ['?', 0.5],
      ['⚡', 0.7], ['⇒ Attention', 0.7], ['↶ Self-Reference', 0.7], ['∧', 0.6],
      ['↭', 0.6], ['▷◁', 0.6]
    ]);

    // ============================================
    // STATE MANAGEMENT
    // ============================================
    const state = {
      apiKey: '',
      isProcessing: false,
      sessionStats: {
        totalApiCalls: 0,
        totalCacheHits: 0,
        totalCostCents: 0,
      }
    };
    
    // AbortController stored separately to avoid cloning issues
    let currentAbortController = null;

    // ============================================
    // DOM ELEMENTS
    // ============================================
    const elements = {
      log: document.getElementById('log'),
      input: document.getElementById('command-input'),
      sendBtn: document.getElementById('send-btn'),
      cancelBtn: document.getElementById('cancel-btn'),
      apiModal: document.getElementById('api-modal'),
      apiKeyInput: document.getElementById('api-key-input'),
      apiConfirmBtn: document.getElementById('api-confirm'),
      apiCancelBtn: document.getElementById('api-cancel'),
      cacheHitRate: document.getElementById('cache-hit-rate'),
      cachedTokens: document.getElementById('cached-tokens'),
      sessionCost: document.getElementById('session-cost'),
    };

    // ============================================
    // UTILITY FUNCTIONS
    // ============================================
    function sanitizeInput(text) {
      const div = document.createElement('div');
      div.textContent = text;
      return div.innerHTML;
    }

    function tokenize(text) {
      if (!text) return [];
      return text.trim()
        .split(/[^\p{L}\p{N}\-']+/u)
        .filter(Boolean)
        .map(t => t.toLowerCase());
    }

    function countTokens(text) {
      return tokenize(text).length;
    }

    function estimateCost(apiCalls) {
      return apiCalls * CONFIG.ESTIMATED_COST_PER_API_CALL;
    }

    function formatCurrency(cents) {
      return `$${(cents / 100).toFixed(2)}`;
    }

    function highlightJSON(json) {
      const jsonString = typeof json === 'string' ? json : JSON.stringify(json, null, 2);
      return jsonString
        .replace(/(&)/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/\"(.*?)\"(?=\s*:)/g, '<span class="json-key">"$1"</span>')
        .replace(/:"(.*?)"/g, ':<span class="json-string">"$1"</span>')
        .replace(/:(\s*)(-?\d+(?:\.\d+)?)/g, ':$1<span class="json-number">$2</span>')
        .replace(/:(\s*)(true|false)/gi, ':$1<span class="json-boolean">$2</span>')
        .replace(/:(\s*)(null)/gi, ':$1<span class="json-boolean">$2</span>');
    }

    // ============================================
    // LOGGING FUNCTIONS
    // ============================================
    function addLogEntry(content, type = 'info') {
      const entry = document.createElement('div');
      entry.className = `log-entry ${type}`;
      const timestamp = new Date().toLocaleTimeString();
      entry.innerHTML = `<div class="timestamp">${timestamp}</div>${content}`;
      elements.log.appendChild(entry);
      elements.log.scrollTo({ top: elements.log.scrollHeight, behavior: 'smooth' });
      return entry;
    }

    function logStatus(message) {
      return addLogEntry(`<div class="processing-indicator"><span class="spinner"></span>${message}</div>`, 'status');
    }

    function logError(message) {
      return addLogEntry(`🔴 ${sanitizeInput(message)}`, 'error');
    }

    function logSuccess(message) {
      return addLogEntry(`✅ ${sanitizeInput(message)}`, 'success');
    }

    function logWarning(message) {
      return addLogEntry(`⚠️ ${sanitizeInput(message)}`, 'warning');
    }

    // ============================================
    // STATS UPDATES
    // ============================================
    function updateStats() {
      const { totalApiCalls, totalCacheHits, totalCostCents } = state.sessionStats;
      const totalRequests = totalApiCalls + totalCacheHits;
      const hitRate = totalRequests > 0 
        ? ((totalCacheHits / totalRequests) * 100).toFixed(1) + '%'
        : '—';
      
      elements.cacheHitRate.textContent = hitRate;
      elements.cachedTokens.textContent = getCachedTokenCount();
      elements.sessionCost.textContent = formatCurrency(totalCostCents);
    }

    function getCachedTokenCount() {
      const keys = Object.keys(localStorage).filter(k => k.startsWith('hlsf_token_'));
      return keys.length;
    }

    // ============================================
    // CACHE MANAGEMENT
    // ============================================
    function getCacheKey(token) {
      return `hlsf_token_${token.toLowerCase()}`;
    }

    function getFromCache(token) {
      try {
        const raw = localStorage.getItem(getCacheKey(token));
        if (!raw) return null;
        const data = JSON.parse(raw);
        state.sessionStats.totalCacheHits++;
        updateStats();
        return data;
      } catch (err) {
        console.error('Cache read error:', err);
        return null;
      }
    }

    function saveToCache(token, data) {
      try {
        localStorage.setItem(getCacheKey(token), JSON.stringify({
          ...data,
          cached_at: new Date().toISOString()
        }));
      } catch (err) {
        if (err.name === 'QuotaExceededError') {
          logWarning('Cache storage full. Consider clearing old data with /reset');
        } else {
          console.error('Cache write error:', err);
        }
      }
    }

    // ============================================
    // OPENAI API
    // ============================================
    async function callOpenAI(messages, options = {}) {
      if (!state.apiKey) {
        throw new Error('No API key configured');
      }

      const body = {
        model: options.model || CONFIG.DEFAULT_MODEL,
        messages,
        max_tokens: options.max_tokens || 1000,
        temperature: options.temperature || 0.7,
      };

      let attempt = 0;
      const maxAttempts = options.retries || CONFIG.MAX_RETRY_ATTEMPTS;

      while (attempt < maxAttempts) {
        // Check if cancelled before each attempt
        if (currentAbortController?.signal.aborted) {
          const error = new Error('Request cancelled');
          error.name = 'AbortError';
          throw error;
        }

        attempt++;
        try {
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${state.apiKey}`,
            },
            body: JSON.stringify(body),
          });

          if (response.status === 429 && attempt < maxAttempts) {
            const delay = CONFIG.RETRY_BASE_DELAY_MS * Math.pow(2, attempt - 1);
            await new Promise(resolve => setTimeout(resolve, delay));
            continue;
          }

          if (!response.ok) {
            const errorText = await response.text();
            let errorMessage = `OpenAI API error (${response.status})`;
            
            try {
              const errorData = JSON.parse(errorText);
              if (errorData.error?.message) {
                errorMessage = errorData.error.message;
              }
            } catch (e) {
              // If not JSON, use the raw text
              if (errorText) errorMessage = errorText;
            }
            
            // Provide helpful hints
            if (response.status === 401) {
              errorMessage = 'Invalid API key. Please check your OpenAI API key and try again.';
            } else if (response.status === 403) {
              errorMessage = 'Access forbidden. Your API key may not have permission or your account may need billing setup.';
            } else if (response.status === 429) {
              errorMessage = 'Rate limit exceeded. Please wait a moment and try again.';
            }
            
            throw new Error(errorMessage);
          }

          const data = await response.json();
          
          // Track cost
          state.sessionStats.totalApiCalls++;
          state.sessionStats.totalCostCents += Math.ceil(CONFIG.ESTIMATED_COST_PER_API_CALL * 100);
          updateStats();

          return data.choices?.[0]?.message?.content?.trim() || '';
        } catch (err) {
          if (err.name === 'AbortError') {
            throw err;
          }
          
          // Better error messages for network issues
          if (err.message === 'Failed to fetch') {
            throw new Error('Network error: Unable to reach OpenAI API. Please check your internet connection.');
          }
          
          if (attempt === maxAttempts) {
            throw err;
          }
        }
      }
    }

    // ============================================
    // ADJACENCY FETCHING
    // ============================================
    async function fetchAdjacency(token, context) {
      // Check if cancelled
      if (currentAbortController?.signal.aborted) {
        throw new Error('AbortError');
      }

      // Check cache first
      const cached = getFromCache(token);
      if (cached) {
        return { ...cached, cache_hit: true };
      }

      if (!state.apiKey) {
        return { token, relationships: {}, offline: true };
      }

      const prompt = `Token: "${token}"
Context: "${context}"

For this token, identify the most relevant adjacent tokens across the 50 Pentacognon relationship types. For each relationship type that applies, provide 0-10 related tokens with weights from 0.01 to 1.00.

Relationship types:
≡ Identity, ⊃ Contains, ⊂ Is Contained By, ≈ Variant, ∈ Is Instance Of, ∋ Has Instance, ⊤ Is Type Of, ⊥ Has Type, ⊏ Part Of, ⊐ Composes, ↔ Mirrors, ⇌ Inverts, ∥ Parallel To, ∼ Adjacent To, → Next, ⇒ Sequence Of, ⇐ Preceded By, ↠ Follows, ↗ Spatially Above, ↘ Spatially Below, ⇝ Symbolically Supports, ⇂ Symbolically Depends, ≠ Contrasts, ⊕ Complements, ⊛ Associated With, ∝ Correlates With, ⇝ Causes, ⇐ Caused By, ∗ Evokes, ≜ Represents, ⋆ Symbolizes, 7→ Refers To, ⊢ Defines, ⊣ Is Defined By, ↷ Transforms To, ↶ Transformed From, ◦ Functions As, |= Interpreted As, ◁ Used With, ⇄ Co-occurs With, ⊗ Synthesizes, ÷ Divides Into, ⊘ Opposes, × Rejects, ¬ Negates, † Destroys, ⊠ Blocks, /∈ Invalidates, ⊬ Contradicts, ⊩ Asserts, ⊨ Provides Evidence, ? Uncertainty, ⚡ Memory, ⇒ Attention, ↶ Self-Reference, ∧ Perspective, ↭ Continuity, ▷◁ Relationality

Return as JSON:
{
  "token": "${token}",
  "relationships": {
    "≡": [{"token": "...", "weight": 0.95}],
    ...
  }
}

Only include relationship types that apply. Leave others empty or omit.`;

      const content = await callOpenAI([
        { role: 'system', content: 'You are an HLSF token adjacency analyzer.' },
        { role: 'user', content: prompt },
      ]);

      try {
        const jsonStart = content.indexOf('{');
        const jsonEnd = content.lastIndexOf('}');
        const jsonText = content.slice(jsonStart, jsonEnd + 1);
        const parsed = JSON.parse(jsonText);
        
        saveToCache(token, parsed);
        return { ...parsed, cache_hit: false };
      } catch (err) {
        logError(`Failed to parse adjacency for "${token}"`);
        return { token, relationships: {}, error: err.message };
      }
    }

    async function batchFetchAdjacencies(tokens, context, label) {
      const statusEntry = logStatus(`⏳ Fetching adjacencies for ${label}...`);
      const results = new Map();
      const uniqueTokens = [...new Set(tokens)];
      
      let processed = 0;
      const concurrency = CONFIG.MAX_CONCURRENCY;
      
      for (let i = 0; i < uniqueTokens.length; i += concurrency) {
        // Check for cancellation
        if (currentAbortController?.signal.aborted) {
          statusEntry.innerHTML = `⚠️ ${label} adjacencies cancelled (${processed}/${uniqueTokens.length})`;
          break;
        }
        
        const batch = uniqueTokens.slice(i, i + concurrency);
        const promises = batch.map(token => fetchAdjacency(token, context));
        const batchResults = await Promise.allSettled(promises);
        
        batchResults.forEach((result, idx) => {
          if (result.status === 'fulfilled') {
            results.set(batch[idx], result.value);
          } else {
            logError(`Failed to fetch adjacency for "${batch[idx]}"`);
          }
        });
        
        processed += batch.length;
        statusEntry.innerHTML = `⏳ Fetching adjacencies for ${label}... (${processed}/${uniqueTokens.length})`;
      }
      
      const cacheHits = Array.from(results.values()).filter(r => r.cache_hit).length;
      statusEntry.innerHTML = `✅ Completed ${label} adjacencies (${cacheHits} cached, ${results.size - cacheHits} new)`;
      
      return results;
    }

    // ============================================
    // ANALYSIS FUNCTIONS
    // ============================================
    function calculateAttentionScores(matrices) {
      for (const entry of matrices.values()) {
        const relationships = entry?.relationships || {};
        let weightSum = 0;
        let totalEdges = 0;
        
        for (const [relation, edges] of Object.entries(relationships)) {
          const priority = RELATIONSHIP_PRIORITIES.get(relation) || 0.3;
          if (Array.isArray(edges)) {
            for (const edge of edges) {
              const weight = Number(edge.weight) || 0;
              weightSum += weight * priority;
              totalEdges++;
            }
          }
        }
        
        entry.attention_score = totalEdges > 0 ? Number((weightSum / totalEdges).toFixed(3)) : 0;
        entry.total_relationships = totalEdges;
      }
      return matrices;
    }

    // ============================================
    // COMMAND HANDLING
    // ============================================
    function isCommand(input) {
      return input.startsWith('/');
    }

    async function handleCommand(cmd) {
      const [command, ...args] = cmd.slice(1).split(/\s+/);
      
      switch (command.toLowerCase()) {
        case 'clear':
          elements.log.innerHTML = '';
          logSuccess('Log cleared');
          break;
          
        case 'reset':
          if (confirm('Clear all cached adjacency data?')) {
            const keys = Object.keys(localStorage).filter(k => k.startsWith('hlsf_token_'));
            keys.forEach(k => localStorage.removeItem(k));
            updateStats();
            logSuccess(`Cleared ${keys.length} cached tokens`);
          }
          break;
          
        case 'stats':
          const { totalApiCalls, totalCacheHits, totalCostCents } = state.sessionStats;
          const total = totalApiCalls + totalCacheHits;
          const hitRate = total > 0 ? ((totalCacheHits / total) * 100).toFixed(1) : 0;
          addLogEntry(`
            <strong>Session Statistics:</strong><br>
            • Total requests: ${total}<br>
            • Cache hits: ${totalCacheHits} (${hitRate}%)<br>
            • API calls: ${totalApiCalls}<br>
            • Session cost: ${formatCurrency(totalCostCents)}<br>
            • Cached tokens: ${getCachedTokenCount()}
          `);
          break;
          
        case 'help':
          addLogEntry(`
            <strong>Available Commands:</strong><br>
            /clear - Clear the log<br>
            /reset - Clear cached adjacency data<br>
            /stats - Show session statistics<br>
            /help - Show this help message
          `);
          break;
          
        default:
          logError(`Unknown command: ${command}`);
      }
    }

    // ============================================
    // MAIN PROCESSING
    // ============================================
    async function processPrompt(prompt) {
      if (state.isProcessing) return;
      
      state.isProcessing = true;
      currentAbortController = new AbortController();
      elements.sendBtn.disabled = true;
      elements.cancelBtn.style.display = 'inline-block';
      elements.input.disabled = true;

      const startTime = performance.now();

      try {
        // Validate input
        const tokens = tokenize(prompt);
        if (tokens.length === 0) {
          logError('Prompt cannot be empty');
          return;
        }
        if (tokens.length > CONFIG.MAX_TOKENS_PER_PROMPT) {
          logError(`Prompt exceeds ${CONFIG.MAX_TOKENS_PER_PROMPT} token limit (${tokens.length} tokens)`);
          return;
        }

        // Estimate cost
        const estimatedApiCalls = tokens.length * 2 + 3; // Rough estimate
        const estimatedCost = estimateCost(estimatedApiCalls);
        addLogEntry(`
          <div class="cost-estimate">
            <div class="cost-estimate-title">📊 Processing Estimate</div>
            • Input tokens: ${tokens.length}<br>
            • Estimated API calls: ~${estimatedApiCalls}<br>
            • Estimated cost: ~${formatCurrency(Math.ceil(estimatedCost * 100))}
          </div>
        `);

        addLogEntry(`🧮 Processing ${tokens.length} input tokens...`);

        // Step 1: Get initial LLM response
        let initialResponse = '';
        if (state.apiKey) {
          const statusEntry = logStatus('⏳ Generating initial response...');
          initialResponse = await callOpenAI([
            { role: 'system', content: 'You are an expert assistant that provides clear, concise responses.' },
            { role: 'user', content: prompt },
          ]);
          statusEntry.innerHTML = `✅ Initial response generated (${countTokens(initialResponse)} tokens)`;
        } else {
          initialResponse = '⚠️ Offline mode: API key required for live processing';
          logWarning('Skipped LLM call (offline mode)');
        }

        // Step 2: Fetch adjacencies
        const responseTokens = tokenize(initialResponse);
        const [inputMatrices, outputMatrices] = await Promise.all([
          batchFetchAdjacencies(tokens, prompt, 'input'),
          batchFetchAdjacencies(responseTokens, initialResponse, 'output'),
        ]);

        // Step 3: Calculate attention
        calculateAttentionScores(inputMatrices);
        calculateAttentionScores(outputMatrices);

        // Step 4: Generate synthesis
        let synthesis = '';
        if (state.apiKey) {
          const statusEntry = logStatus('⏳ Synthesizing insights...');
          const summaryData = Array.from(inputMatrices.entries())
            .map(([token, data]) => ({ token, attention: data.attention_score }))
            .sort((a, b) => b.attention - a.attention)
            .slice(0, 10);

          synthesis = await callOpenAI([
            { role: 'system', content: 'You analyze token relationships to extract insights.' },
            { role: 'user', content: `Analyze these token attention scores and identify key patterns:\n${JSON.stringify(summaryData, null, 2)}` },
          ]);
          statusEntry.innerHTML = '✅ Synthesis complete';
        }

        // Step 5: Display results
        const processingTime = ((performance.now() - startTime) / 1000).toFixed(1);
        const finalEntry = document.createElement('div');
        finalEntry.className = 'log-entry final-output';
        finalEntry.innerHTML = `
          <div class="timestamp">${new Date().toLocaleTimeString()}</div>
          <div>✓ Processing complete (${processingTime}s)</div>
          <h3>RESPONSE:</h3>
          <pre>${sanitizeInput(initialResponse)}</pre>
          ${synthesis ? `<details><summary>Show insights</summary><pre>${sanitizeInput(synthesis)}</pre></details>` : ''}
          <details>
            <summary>Show adjacency data (${inputMatrices.size + outputMatrices.size} tokens)</summary>
            <div><strong>Input tokens:</strong> ${Array.from(inputMatrices.keys()).slice(0, 10).join(', ')}${inputMatrices.size > 10 ? '...' : ''}</div>
            <div><strong>Output tokens:</strong> ${Array.from(outputMatrices.keys()).slice(0, 10).join(', ')}${outputMatrices.size > 10 ? '...' : ''}</div>
          </details>
        `;
        elements.log.appendChild(finalEntry);
        elements.log.scrollTo({ top: elements.log.scrollHeight, behavior: 'smooth' });

      } catch (err) {
        if (err.name === 'AbortError' || err.message === 'AbortError') {
          logWarning('Processing cancelled');
        } else {
          logError(err.message || 'Processing failed');
          console.error('Processing error:', err);
        }
      } finally {
        state.isProcessing = false;
        currentAbortController = null;
        elements.sendBtn.disabled = false;
        elements.cancelBtn.style.display = 'none';
        elements.input.disabled = false;
        elements.input.value = '';
        elements.input.focus();
      }
    }

    // ============================================
    // EVENT HANDLERS
    // ============================================
    elements.apiConfirmBtn.addEventListener('click', () => {
      const key = elements.apiKeyInput.value.trim();
      if (!key.startsWith('sk-')) {
        logError('Invalid API key format (must start with sk-)');
        return;
      }
      state.apiKey = key;
      elements.apiModal.classList.add('hidden');
      logSuccess('API key configured for this session');
    });

    elements.apiCancelBtn.addEventListener('click', () => {
      elements.apiModal.classList.add('hidden');
      logWarning('Proceeding in offline mode (limited functionality)');
    });

    elements.sendBtn.addEventListener('click', () => {
      const input = elements.input.value.trim();
      if (!input) return;
      
      addLogEntry(`> ${sanitizeInput(input)}`);
      
      if (isCommand(input)) {
        handleCommand(input);
        elements.input.value = '';
      } else {
        processPrompt(input);
      }
    });

    elements.cancelBtn.addEventListener('click', () => {
      if (currentAbortController) {
        currentAbortController.abort();
        logWarning('Cancelling...');
      }
    });

    elements.input.addEventListener('keydown', (e) => {
      if (e.key === 'Enter' && !e.shiftKey) {
        e.preventDefault();
        elements.sendBtn.click();
      }
    });

    // ============================================
    // INITIALIZATION
    // ============================================
    window.addEventListener('beforeunload', () => {
      state.apiKey = ''; // Clear from memory
    });

    updateStats();
    addLogEntry(`
      <strong>Welcome to HLSF Cognition Engine v2.0</strong><br>
      Type a prompt to begin analysis, or use /help for commands.<br>
      <small>⚡ Cached tokens: ${getCachedTokenCount()} | Estimated savings so far: ${formatCurrency(state.sessionStats.totalCacheHits * 2)}</small>
    `);
  </script>
</body>
</html>